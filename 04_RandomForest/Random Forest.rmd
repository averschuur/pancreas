Build RandomForest using training set and make predictions on test set 

#First call the required packages 
```{r}
library('ggplot2')
library('cowplot')
library('randomForest')
library('tidyverse')
library('caret')
```

#Load trainingset and prepare (these is the dataset with a selection of 5000MVP on PanNETs(Chan+DiDomenico), ACC, SPN, PDAC and Normal pancreas(Endo+DiDOmenico))
```{r}
load('T:/pathologie/PRL/Groep-Brosens/2. Anna Vera/2. ACN-SPN-NET/Pancreas-ID/04_RandomForest/5000MVP')
origin <- annodatamerged
rownames(annodatamerged) <- annodatamerged[,1]
annodatamerged[,1:3] <- NULL
annodatamerged[,2:3] <- NULL
data <- annodatamerged
rm(annodatamerged)
```

#Load and prepare test set (UMCU dataset)
```{r}
load('T:/pathologie/PRL/Groep-Brosens/2. Anna Vera/2. ACN-SPN-NET/Pancreas-ID/01_Load&Normalize/PreProcessedDataSets/preprocessedssNoobUMCU14032022.rData')
PD_combined<-read.csv("T:/pathologie/PRL/Groep-Brosens/2. Anna Vera/2. ACN-SPN-NET/Pancreas-ID/00_Methylation Data/PD_Annotation.csv", header=TRUE)
UMCU <- bValsnoobdf
UMCU <- as.data.frame(t(UMCU))

#add collum with Sample_Group
annoUMCU <- merge(PD_combined[,c(3:4)], UMCU, by.x="Sentrix_ID", by.y="row.names", sort = FALSE)
rownames(annoUMCU) <- annoUMCU[,1]
annoUMCU[,1] <- NULL

#select probes in the testset that are in the training dataset
UMCU_select <- UMCU %>%
  select(contains(colnames(data)))
table(colnames(UMCU_select) %in% colnames(data))

#add collum with Sample_Group
annoUMCU_select <- merge(PD_combined[,c(3:4)], UMCU_select, by.x="Sentrix_ID", by.y="row.names", sort = FALSE)
rownames(annoUMCU_select) <- annoUMCU_select[,1]
annoUMCU_select[,1] <- NULL
```

#Set seed to reproduce the results
```{r} 
set.seed(30)
```
#Adjust number of probes of 'trainingset'  to that of 'testset'
```{r}
d <- data %>%
  select(contains(colnames(UMCU_select)))

#Load annotation
PD_combined<-read.csv("T:/pathologie/PRL/Groep-Brosens/2. Anna Vera/2. ACN-SPN-NET/Pancreas-ID/00_Methylation Data/PD_Annotation.csv", header=TRUE)

dd <- merge(PD_combined[,c(3:4)], d, by.x="Sentrix_ID", by.y="row.names", sort = FALSE)
rownames(dd) <- dd[,1]
dd[,1] <- NULL
```

#Build random Forest:
```{r}
dd$Sample_Group <- as.factor(dd$Sample_Group)
model <- randomForest(Sample_Group~., data=dd, proximity=TRUE)
```
##obtain information
```{r}
model
plot(model)
varImpPlot(model)
```

# To check whether 500 trees was enough for optimal classification
```{r}
oob.error.data <- data.frame(
  Trees=rep(1:nrow(model$err.rate), times=3),
  Type=rep(c("OOB", "ACC", "Normal pancreas", "panNET", "PDAC", "SPN"), each=nrow(model$err.rate)),
  Error=c(model$err.rate[,"OOB"], 
    model$err.rate[,"ACC"], 
    model$err.rate[,"Normal pancreas"],
    model$err.rate[,"panNET"],
    model$err.rate[,"PDAC"],
    model$err.rate[,"SPN"]))

ggplot(data=oob.error.data, aes(x=Trees, y=Error)) +
  geom_line(aes(color=Type))
```

#If we want to compare this random forest to others with different values for mtry (to control how many variables are considered at each step)...
```{r}
oob.values <-vector(length=0)
for(i in 1:10) {
  temp.model <- randomForest(Sample_Group~., data=dd, mtry=1, ntree=1000)
  oob.values[i] <- temp.model$err.rate[nrow(temp.model$err.rate),1]
}
oob.values
``` 

```{r}
## find the minimum error
min(oob.values)
## find the optimal value for mtry...
which(oob.values == min(oob.values))
```
## create a model for proximities using the best value for mtry
```{r}
model1 <- randomForest(Sample_Group~., 
                      data=dd,
                      ntree=500, 
                      proximity=TRUE, 
                      mtry=which(oob.values == min(oob.values)))
```

```{r}
model1
plot(model1)
varImpPlot(model1)
```
## Now let's create an MDS-plot to show how the samples are related to each 
## other.
##
## Start by converting the proximity matrix into a distance matrix.
```{r}
distance.matrix <- as.dist(1-model1$proximity)
mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE)

## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)

## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
  X=mds.values[,1],
  Y=mds.values[,2],
  Status=dd$Sample_Group)

ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) + 
  geom_text(aes(color=Status)) +
  theme_bw() +
  xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
  ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
  ggtitle("MDS plot using (1 - Random Forest Proximities)")
ggsave(file="T:/pathologie/PRL/Groep-Brosens/2. Anna Vera/2. ACN-SPN-NET/Pancreas-ID/04_RandomForest/random_forest_mds_plot.pdf")
```

#Prepare data for prediction

# method 1: remove all probes from the training data set which are not in the test dataset
```{r}
## select the probes in trainingset that are also in test dataset
ddd <- dd %>%
     select(contains(colnames(UMCU)))
table(colnames(ddd) %in% colnames(annoUMCU))

## add collum with sample_group
ddd <- merge(PD_combined[,c(3:4)], ddd, by.x="Sentrix_ID", by.y="row.names", sort = FALSE)
rownames(ddd) <- ddd[,1]
ddd[,1] <- NULL

## run random forest again
ddd$Sample_Group <- as.factor(ddd$Sample_Group)
model2 <- randomForest(Sample_Group~., data=ddd, proximity=TRUE)

## to control how many variables are considered at each step
oob.values <-vector(length=0)
for(i in 1:10) {
  temp.model <- randomForest(Sample_Group~., data=ddd, mtry=1, ntree=1000)
  oob.values[i] <- temp.model$err.rate[nrow(temp.model$err.rate),1]
}

## create a model for proximities using the best value for mtry
model3 <- randomForest(Sample_Group~., 
                      data=ddd,
                      ntree=500, 
                      proximity=TRUE, 
                      mtry=which(oob.values == min(oob.values)))
model3


## now make a prediction and save in annotUMCU$prediction
annoUMCU$prediction <- as.factor(predict(model3, newdata=annoUMCU, type = "class"))

#merge levels of training and test dataset together and print the confusionMatrix
u <- union(annoUMCU$prediction, annoUMCU$Sample_Group)
t <- table(factor(annoUMCU$prediction, u), factor(annoUMCU$Sample_Group, u))
confusionMatrix(t)

## optional: remove Mixed ACC-NETG3 from test dataframe
annoUMCU_select <- annoUMCU %>%
  filter(!Sample_Group %in% "Mixed ACC-NETG3")

## make prediction nagain
annoUMCU_select$prediction <- as.factor(predict(model3, newdata=annoUMCU_select, type = "class"))

## obtain confusionMatrix
u <- union(annoUMCU_select$prediction, annoUMCU_select$Sample_Group)
t <- table(factor(annoUMCU_select$prediction, u), factor(annoUMCU_select$Sample_Group, u))
confusionMatrix(t)
```

# Check the misclassifications in the model
```{r}
model3$votes

ddd$prediction <- as.factor(predict(model3, newdata=ddd, type = "class"))
confusionMatrix(table(ddd$prediction,ddd$Sample_Group))

test <- ddd %>%
    select("Sample_Group", "prediction")

View(test)
#strange! Sample_Group and prediction are identical!
```


# method 2: imputate the missing variables that are missing in the training dataset but not in de test dataset
```{r}
#first, indicate which variables are present in the training dataset but not in the test set
table(colnames(UMCU) %in% colnames(data)) #--> er zitten 4968 variabelen uit trainingset in de testset; dus er missen 33 variabelen:
table(colnames(data) %in% colnames(UMCU_select))

#select the 33 probes that are not in the testset
UMCU_missing <- data %>%
     select(!contains(colnames(UMCU_select))) #this does not work
#or
UMCU_missing <- data %>%
  select(colnames(data) %notin% colnames(UMCU_select))#this does not work neither

#if it works, than merge variables with test set

#Then, impute data
data.imputed <- rfImpute(, colnames(data), data=UMCU, iter=6 )
```
